{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oa9Yfd8nIVeU"
      },
      "source": [
        "1. importing and configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708,
          "referenced_widgets": [
            "33873130436c40d2b85e262b36283a56",
            "804c6389e6e94733aeff200cd7189c6f",
            "62825d0990894289a5d7f9ae9d39b17b",
            "3127268ffeea41b09309b94385687bd5",
            "768b723f28d04c10af6aa10e2b26ec66",
            "59a479e0855c471db290c5727ac59b65",
            "d55f1f5afc464006a83df29ddfa9eb96",
            "e688448a03af445da902012a19f880a6",
            "0e28cceff4324b8d92201c4af13cf8f4",
            "bf3a3c52b16547b0a1c5ae25ec6b3b4a",
            "356281dccc6649b7bb9ce7d89e223007",
            "6af56b56cf954d2c8ca164aa4b39a49b",
            "d05f3c3782fc47f0a83301b866a0e730",
            "4ed6d17aa45c44a99cf2ba0f095e6d37",
            "db4027be24694577ade3a005497bb547",
            "747c1326d37547b0990cff2f15ce4493",
            "38d1be4141f94ab0825a9c1ec3fc1175"
          ]
        },
        "id": "FcUXt_gPAy7w",
        "outputId": "c06881fc-83dd-412c-ae50-9b6ad8622ad4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33873130436c40d2b85e262b36283a56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install transformers\n",
        "import pandas as pd\n",
        "import requests\n",
        "import nltk\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import glob\n",
        "import gzip\n",
        "import json\n",
        "import kagglehub\n",
        "import re\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "from transformers import pipeline\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from scipy.sparse import hstack\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "notebook_login(\"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\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWorH4RFIauf"
      },
      "source": [
        "2. cleaning the kaggle dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvDKp7IQBlAZ",
        "outputId": "604822a6-f0e1-4ca3-e713-39ad0efb28db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3517965814.py:2: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
            "  df_kaggle = kagglehub.load_dataset(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1100, 6)\n",
            "business_name      object\n",
            "author_name        object\n",
            "text               object\n",
            "photo              object\n",
            "rating              int64\n",
            "rating_category    object\n",
            "dtype: object\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3517965814.py:13: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df_kaggle = df_kaggle.applymap(lambda s: s.lower() if isinstance(s, str) else s) # convert all string columns to lowercase\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "file_path = \"reviews.csv\"\n",
        "df_kaggle = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"denizbilginn/google-maps-restaurant-reviews\",\n",
        "  file_path,\n",
        ")\n",
        "\n",
        "print(df_kaggle.shape) # (1100, 6)\n",
        "\n",
        "print(df_kaggle.dtypes) # check data type of each column\n",
        "df_kaggle.isnull().values.any() # check for missing values: false\n",
        "df_kaggle.duplicated().any() # check for exact duplicate rows: false\n",
        "df_kaggle = df_kaggle.applymap(lambda s: s.lower() if isinstance(s, str) else s) # convert all string columns to lowercase\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "stop = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "  if not isinstance(text, str):\n",
        "    return \"\"\n",
        "\n",
        "  # remove leading/trailing whitespace\n",
        "  text = text.strip()\n",
        "\n",
        "  # remove punctuation, numbers, special characters\n",
        "  text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "\n",
        "  # collapse multiple spaces\n",
        "  text = re.sub(r\"\\s+\", \" \", text)\n",
        "\n",
        "  # remove stopwords and lemmatize\n",
        "  words = [lemmatizer.lemmatize(w) for w in text.split() if w not in stop]\n",
        "  text = \" \".join(words)\n",
        "\n",
        "  return text\n",
        "\n",
        "df_kaggle_cleaned = df_kaggle\n",
        "df_kaggle_cleaned[\"clean_text\"] = df_kaggle_cleaned[\"text\"].apply(clean_text) # create a new column clean_text\n",
        "\n",
        "df_kaggle_cleaned.rename(columns={\n",
        "    \"business_name\": \"location_name\",\n",
        "    \"text\": \"review_text\",\n",
        "    \"author_name\": \"review_id\"\n",
        "}, inplace=True)\n",
        "\n",
        "df_kaggle_cleaned.head() # check first 5 rows of the dataset\n",
        "\n",
        "df_kaggle_cleaned.to_csv(\"kaggle_cleaned.csv\", index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoVIV5FNIJ2T"
      },
      "source": [
        "3. cleaning the google local reviews dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pczw17PkCrd8",
        "outputId": "701ae099-12e3-48c4-c81b-3813a3fdb74e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Alabama...\n",
            "Added 2000 reviews from Alabama to master CSV\n",
            "Processing Alaska...\n",
            "Added 2000 reviews from Alaska to master CSV\n",
            "master CSV: master_csv.csv\n",
            "   review_id     location_name  \\\n",
            "0          0  Unknown Business   \n",
            "1          1  Unknown Business   \n",
            "2          2  Unknown Business   \n",
            "3          3  Unknown Business   \n",
            "4          4  Unknown Business   \n",
            "\n",
            "                                         review_text  \\\n",
            "0                                       great always   \n",
            "1                   super selection unbeatable price   \n",
            "2                     get everything need good staff   \n",
            "3                          bit quiet mall much going   \n",
            "4  bartender staff person courteous helpful nice ...   \n",
            "\n",
            "                                          clean_text  \n",
            "0                                       great always  \n",
            "1                   super selection unbeatable price  \n",
            "2                     get everything need good staff  \n",
            "3                          bit quiet mall much going  \n",
            "4  bartender staff person courteous helpful nice ...  \n",
            "(4000, 4)\n",
            "Missing values: review_id        0\n",
            "location_name    0\n",
            "review_text      6\n",
            "clean_text       6\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#nltk setup\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "#functions set up\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)  # remove punctuation, numbers, special characters\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()  # collapse spaces\n",
        "    tokens = text.split()\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens if t not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "def process_gzip_file_stream(file_path, max_samples=1000):\n",
        "    \"\"\"Process a .json.gz file line by line with reservoir sampling.\"\"\"\n",
        "    sampled_reviews = []\n",
        "    try:\n",
        "        with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                obj = json.loads(line)\n",
        "                review = None\n",
        "                for key in obj.keys():\n",
        "                    if 'review' in key.lower() or 'text' in key.lower():\n",
        "                        review = obj[key]\n",
        "                        break\n",
        "                if review is None:\n",
        "                    continue\n",
        "\n",
        "                # reservoir sampling\n",
        "                if len(sampled_reviews) < max_samples:\n",
        "                    sampled_reviews.append(review)\n",
        "                else:\n",
        "                    i = random.randint(0, len(sampled_reviews))\n",
        "                    if i < max_samples:\n",
        "                        sampled_reviews[i] = review\n",
        "\n",
        "        # clean reviews\n",
        "        sampled_reviews = [clean_text(r) for r in sampled_reviews]\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            \"review_id\": range(len(sampled_reviews)),\n",
        "            \"location_name\": \"Unknown Business\",\n",
        "            \"review_text\": sampled_reviews,\n",
        "            \"clean_text\": sampled_reviews\n",
        "        })\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "base_url = \"https://mcauleylab.ucsd.edu/public_datasets/gdrive/googlelocal\"\n",
        "states = [\"Alabama\", \"Alaska\"] # add in more states to increase the dataset\n",
        "os.makedirs(\"google_reviews\", exist_ok=True)\n",
        "max_samples_per_state = 2000 # sample size\n",
        "master_csv = \"master_csv.csv\"\n",
        "\n",
        "# remove existing master CSV\n",
        "if os.path.exists(master_csv):\n",
        "    os.remove(master_csv)\n",
        "\n",
        "#download and process files\n",
        "for state in states:\n",
        "    file_name = f\"review-{state}_10.json.gz\"\n",
        "    file_url = f\"{base_url}/{file_name}\"\n",
        "    local_path = os.path.join(\"google_reviews\", file_name)\n",
        "\n",
        "    if not os.path.exists(local_path):\n",
        "        print(f\"Downloading {file_name}...\")\n",
        "        r = requests.get(file_url)\n",
        "        if r.status_code == 200:\n",
        "            with open(local_path, \"wb\") as f:\n",
        "                f.write(r.content)\n",
        "        else:\n",
        "            print(f\"Failed to download {file_name}: {r.status_code}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"Processing {state}...\")\n",
        "    df_state = process_gzip_file_stream(local_path, max_samples=max_samples_per_state)\n",
        "\n",
        "    if not df_state.empty:\n",
        "        # append to master CSV\n",
        "        df_state.to_csv(master_csv, index=False, mode='a', header=not os.path.exists(master_csv))\n",
        "        print(f\"Added {len(df_state)} reviews from {state} to master CSV\")\n",
        "    else:\n",
        "        print(f\"No reviews sampled for {state}\")\n",
        "\n",
        "print(\"master CSV:\", master_csv)\n",
        "\n",
        "#check\n",
        "df = pd.read_csv(master_csv)\n",
        "print(df.head())\n",
        "print(df.shape)\n",
        "print(\"Missing values:\", df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmd322SaIiaJ"
      },
      "source": [
        "4. model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0nV1MLnAxvd",
        "outputId": "8c08f0c7-ff0a-4295-fd35-3b44a99cc1a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "detected CSV file: master_csv.csv\n",
            "Loaded 4000 reviews.\n",
            "TEST MODE ON: Using random sample of 100 reviews.\n",
            "Fetching store categories...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running batched LLM classification...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [17:08<00:00, 257.17s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample outputs:\n",
            "                                          clean_text    llm_category\n",
            "0  translated google good food original por tener...      Irrelevant\n",
            "1                       large assortment information      Irrelevant\n",
            "2                           first time visiting love      Irrelevant\n",
            "3  best chinese restaurant interior alaska know a...  Genuine Review\n",
            "4  fun easily accessible place absorb nature well...      Irrelevant\n",
            "Running ML-based policy flagging...\n",
            "Policy Model: Precision=1.000, Recall=1.000, F1=1.000\n",
            "saved master_csv_classified.csv with categories, sentiment, and ranking.\n"
          ]
        }
      ],
      "source": [
        "# 1. configuration\n",
        "# ----------------\n",
        "\n",
        "INPUT_PATH = \"master_csv.csv\"\n",
        "API_KEY = \"AIzaSyCt_oTJoiaxadSJ27QrISs7gErSaibR888\"  # API key\n",
        "CATEGORIES = [\"Spam\", \"Advertisement\", \"Irrelevant\", \"Rant/Fake Complaint\", \"Genuine Review\"]\n",
        "\n",
        "TEST_MODE = True # optional testing on a sample size; set to FALSE for the full dataset\n",
        "SAMPLE_SIZE = 100 # change this sample size\n",
        "\n",
        "# 2. loading datasets\n",
        "# -------------------\n",
        "\n",
        "# inputs must be either csv or compressed json files\n",
        "def load_reviews(path):\n",
        "    if os.path.isfile(path) and path.endswith(\".csv\"):\n",
        "        # single csv\n",
        "        print(f\"detected CSV file: {path}\")\n",
        "        df = pd.read_csv(path)\n",
        "\n",
        "    elif os.path.isdir(path):\n",
        "        # folder of compressed json files\n",
        "        print(f\"detected folder: {path}\")\n",
        "        files = glob.glob(f\"{path}/*.json.gz\")\n",
        "        print(f\"Found {len(files)} JSON review files.\")\n",
        "\n",
        "        all_reviews = []\n",
        "        for f in files:\n",
        "            with gzip.open(f, \"rt\", encoding = \"utf-8\") as fh:\n",
        "                for line in fh:\n",
        "                    all_reviews.append(json.loads(line))\n",
        "        df = pd.DataFrame(all_reviews)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"invalid path: {path}.\")\n",
        "\n",
        "    return df\n",
        "\n",
        "df = load_reviews(INPUT_PATH)\n",
        "print(f\"Loaded {len(df)} reviews.\")\n",
        "\n",
        "# 3. sampling for testing (optional)\n",
        "# ----------------------------------\n",
        "\n",
        "if TEST_MODE:\n",
        "    if len(df) > SAMPLE_SIZE:\n",
        "        df = df.sample(SAMPLE_SIZE, random_state=42).reset_index(drop=True)\n",
        "        print(f\"TEST MODE ON: Using random sample of {SAMPLE_SIZE} reviews.\")\n",
        "    else:\n",
        "        print(f\"Dataset has only {len(df)} reviews, using all.\")\n",
        "else:\n",
        "    print(\"FULL MODE: Processing the entire dataset.\")\n",
        "\n",
        "# standardise column names\n",
        "if \"review\" in df.columns:\n",
        "    df.rename(columns={\"review\": \"clean_text\"}, inplace=True)\n",
        "if \"text\" in df.columns and \"clean_text\" not in df.columns:\n",
        "    df.rename(columns={\"text\": \"clean_text\"}, inplace=True)\n",
        "\n",
        "# ensure required columns\n",
        "if \"business_name\" not in df.columns:\n",
        "    df[\"business_name\"] = \"Unknown\"\n",
        "df[\"clean_text\"] = df[\"clean_text\"].fillna(\"\").astype(str)\n",
        "\n",
        "# 4. store categories by google API\n",
        "# -------------------------------\n",
        "def get_store_category(store_name, retries=3):\n",
        "    if not isinstance(store_name, str) or store_name.strip() == \"\" or store_name == \"Unknown\":\n",
        "        return []\n",
        "    url = \"https://maps.googleapis.com/maps/api/place/textsearch/json\"\n",
        "    params = {\"query\": store_name, \"key\": API_KEY}\n",
        "    for _ in range(retries):\n",
        "        try:\n",
        "            resp = requests.get(url, params=params).json()\n",
        "            if \"results\" in resp and len(resp[\"results\"]) > 0:\n",
        "                return resp[\"results\"][0].get(\"types\", [])\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching category for {store_name}: {e}\")\n",
        "        time.sleep(1)\n",
        "    return []\n",
        "\n",
        "print(\"Fetching store categories...\")\n",
        "df[\"store_category\"] = df[\"business_name\"].apply(get_store_category)\n",
        "\n",
        "# 5. LLM classification in batches\n",
        "# --------------------------------\n",
        "\n",
        "# load model\n",
        "classifier = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=\"google/flan-t5-large\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "def clean_output(output, categories):\n",
        "    \"\"\"Normalize model output to one of the defined categories.\"\"\"\n",
        "    output = output.strip().replace('\"', '').replace(\"'\", \"\")\n",
        "    for c in categories:\n",
        "        if c.lower() in output.lower():\n",
        "            return c\n",
        "    return \"Unknown\"\n",
        "\n",
        "def batch_classify(df, categories, batch_size=32):\n",
        "    \"\"\"Classify reviews in batches to speed up inference.\"\"\"\n",
        "    results = []\n",
        "    for start in tqdm(range(0, len(df), batch_size)):\n",
        "        end = min(start + batch_size, len(df))\n",
        "        batch = df.iloc[start:end]\n",
        "\n",
        "        # build prompts\n",
        "        prompts = []\n",
        "        for _, row in batch.iterrows():\n",
        "            review = row[\"clean_text\"]\n",
        "            store = row.get(\"business_name\", \"Unknown\")\n",
        "            store_category = row.get(\"store_category\", [])\n",
        "\n",
        "            if not isinstance(review, str) or not review.strip():\n",
        "                prompts.append(\"Classify as Unknown.\")\n",
        "                continue\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            You are moderating Google location reviews.\n",
        "\n",
        "            Store: {store}\n",
        "            Store categories: {store_category}\n",
        "\n",
        "            Classify the following review into one of the categories: {categories}.\n",
        "\n",
        "            Rules:\n",
        "            If the review is about the store's products or services -> Genuine Review\n",
        "            If the review is about something unrelated to the store -> Irrelevant\n",
        "            If the review is promotional or contains links -> Advertisement\n",
        "            If the review is gibberish -> Spam\n",
        "            If the review is a complaint but the user mentions they have never visited the business -> Rant/Fake Complaint\n",
        "\n",
        "            Examples:\n",
        "            Review: \"Buy now at our website\" -> Advertisement\n",
        "            Review: \"Visit us at https://www.tiktok123.com\" -> Advertisement\n",
        "            Review: \"I hate teletubbies, they are so ugly\" -> Irrelevant\n",
        "            Review: \"I heard that the food is nice, but I have not been there before\" -> Rant/Fake Complaint\n",
        "            Review: \"Great coffee, cozy atmosphere for getting some work done\" -> Genuine Review\n",
        "            Review: \"The service was really bad, but the food was good\" -> Genuine Review\n",
        "            Review: \"kjvsndkcn,sdmc e $#17*\" -> Spam\n",
        "\n",
        "            Review: \"{review}\"\n",
        "            Answer with exactly one category: Spam, Advertisement, Irrelevant, Rant/Fake Complaint, Genuine Review.\n",
        "            \"\"\"\n",
        "            prompts.append(prompt)\n",
        "\n",
        "        # run the batch at once\n",
        "        outputs = classifier(prompts, max_new_tokens=10, do_sample=False)\n",
        "\n",
        "        # clean outputs\n",
        "        for out in outputs:\n",
        "            label = clean_output(out[\"generated_text\"], categories)\n",
        "            results.append(label)\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"running batched LLM classification...\")\n",
        "df[\"llm_category\"] = batch_classify(df, CATEGORIES, batch_size=32)\n",
        "print(\"sample outputs:\")\n",
        "print(df[[\"clean_text\", \"llm_category\"]].head())\n",
        "\n",
        "# 6. policy flagging & quality scoring\n",
        "# -------------------------------\n",
        "print(\"Running ML-based policy flagging...\")\n",
        "\n",
        "# basic policy flags\n",
        "df[\"review_len\"] = df[\"clean_text\"].apply(lambda x: len(x.split()))\n",
        "df[\"policy_flags\"] = df[\"review_len\"].apply(lambda x: [\"too_short\"] if x < 3 else [])\n",
        "\n",
        "# sentiment\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "df[\"sentiment\"] = df[\"clean_text\"].apply(lambda x: sia.polarity_scores(x)[\"compound\"])\n",
        "\n",
        "# TF-IDF + randomforest\n",
        "tfidf = TfidfVectorizer(max_features=500)\n",
        "X_tfidf = tfidf.fit_transform(df[\"clean_text\"])\n",
        "meta_features = df[[\"review_len\", \"sentiment\"]].values\n",
        "X = hstack([X_tfidf, meta_features])\n",
        "labels = df[\"policy_flags\"].apply(lambda x: 1 if len(x) > 0 else 0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred = rf_model.predict(X_test)\n",
        "print(f\"Policy Model: Precision={precision_score(y_test, y_pred):.3f}, Recall={recall_score(y_test, y_pred):.3f}, F1={f1_score(y_test, y_pred):.3f}\")\n",
        "\n",
        "df[\"policy_violation\"] = rf_model.predict(X)\n",
        "\n",
        "# quality scoring\n",
        "df[\"quality_score\"] = df[\"review_len\"]*0.7 - df[\"policy_violation\"]*1.0\n",
        "df[\"rank\"] = df[\"quality_score\"].rank(ascending=False)\n",
        "\n",
        "# 7. save output\n",
        "# --------------\n",
        "if INPUT_PATH.endswith(\".csv\"):\n",
        "    OUTPUT_FILE = INPUT_PATH.replace(\".csv\", \"_classified.csv\")\n",
        "else:\n",
        "    OUTPUT_FILE = \"classified_reviews.csv\"\n",
        "\n",
        "df.to_csv(OUTPUT_FILE, index=False)\n",
        "print(f\"saved {OUTPUT_FILE} with categories, sentiment, and ranking.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e28cceff4324b8d92201c4af13cf8f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3127268ffeea41b09309b94385687bd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_6af56b56cf954d2c8ca164aa4b39a49b",
            "style": "IPY_MODEL_d05f3c3782fc47f0a83301b866a0e730",
            "value": true
          }
        },
        "33873130436c40d2b85e262b36283a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_804c6389e6e94733aeff200cd7189c6f",
              "IPY_MODEL_62825d0990894289a5d7f9ae9d39b17b",
              "IPY_MODEL_3127268ffeea41b09309b94385687bd5",
              "IPY_MODEL_768b723f28d04c10af6aa10e2b26ec66",
              "IPY_MODEL_59a479e0855c471db290c5727ac59b65"
            ],
            "layout": "IPY_MODEL_d55f1f5afc464006a83df29ddfa9eb96"
          }
        },
        "356281dccc6649b7bb9ce7d89e223007": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38d1be4141f94ab0825a9c1ec3fc1175": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ed6d17aa45c44a99cf2ba0f095e6d37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59a479e0855c471db290c5727ac59b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_747c1326d37547b0990cff2f15ce4493",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_38d1be4141f94ab0825a9c1ec3fc1175",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "62825d0990894289a5d7f9ae9d39b17b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_bf3a3c52b16547b0a1c5ae25ec6b3b4a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_356281dccc6649b7bb9ce7d89e223007",
            "value": ""
          }
        },
        "6af56b56cf954d2c8ca164aa4b39a49b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "747c1326d37547b0990cff2f15ce4493": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "768b723f28d04c10af6aa10e2b26ec66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_4ed6d17aa45c44a99cf2ba0f095e6d37",
            "style": "IPY_MODEL_db4027be24694577ade3a005497bb547",
            "tooltip": ""
          }
        },
        "804c6389e6e94733aeff200cd7189c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e688448a03af445da902012a19f880a6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0e28cceff4324b8d92201c4af13cf8f4",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "bf3a3c52b16547b0a1c5ae25ec6b3b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d05f3c3782fc47f0a83301b866a0e730": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d55f1f5afc464006a83df29ddfa9eb96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "db4027be24694577ade3a005497bb547": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "e688448a03af445da902012a19f880a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}